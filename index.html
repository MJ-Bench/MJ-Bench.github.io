<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description"
    content="A benchmark of Multimodal Reward Models for Text-to-Image Generation.">
  <meta name="keywords" content="Multimodal Code Generation, Large Multimodal Models">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>MJ-Bench: Is Your Multimodal Reward Model Really a Good Judge for Text-to-Image Generation?</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script> -->

  <meta name="viewport" content="width=device-width, initial-scale=1">

  <script src="https://cdn.jsdelivr.net/npm/chart.js@4.4.0/dist/chart.umd.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-datalabels@2.0.0"></script>
  <script
    src="https://cdn.jsdelivr.net/npm/chartjs-plugin-annotation@3.0.1/dist/chartjs-plugin-annotation.min.js"></script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link href="https://unpkg.com/tabulator-tables@5.5.2/dist/css/tabulator_bootstrap4.min.css" rel="stylesheet">
  <script type="text/javascript" src="https://unpkg.com/tabulator-tables@5.5.2/dist/js/tabulator.min.js"></script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.ico">

  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet"
    integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"
    integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p"
    crossorigin="anonymous"></script>

  <link href="https://unpkg.com/tabulator-tables@5.5.2/dist/css/tabulator_bootstrap4.min.css" rel="stylesheet">
  <script type="text/javascript" src="https://unpkg.com/tabulator-tables@5.5.2/dist/js/tabulator.min.js"></script>

  <script src="./static/js/benmark_table.js" type="module"></script>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <!-- <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script> -->
</head>

<body>

  <!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">MJ-Bench: Is Your Multimodal Reward Model Really a Good Judge for Text-to-Image Generation?</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://billchan226.github.io/">Zhaorun Chen</a><sup>*1,2</sup>,</span>
              <span class="author-block">
                <a href="https://duyichao.github.io/">Yichao Du</a><sup>*6</sup>,</span>
              <span class="author-block">
                <a href="./">Zichen Wen</a><sup>*8</sup>,</span>
              <span class="author-block">
                <a href="https://yiyangzhou.github.io/">Yiyang Zhou</a><sup>*1</sup>,</span>
              <span class="author-block">
                <a href="https://gzcch.github.io/">Chenhang Cui</a><sup>13</sup>,</span>
              <span class="author-block">
                <a href="https://zzweng.github.io/">Zhenzhen Weng</a><sup>3</sup>,</span>
              <span class="author-block">
                <a href="https://www.haqtu.me/">Haoqin Tu</a><sup>4</sup>,</span>
              <span class="author-block">
                <a href="https://alecwangcq.github.io/">Chaoqi Wang</a><sup>2</sup>,</span><br>
              <span class="author-block">
                <a href="https://scholars.duke.edu/person/zhengwei.tong">Zhengwei Tong</a><sup>10</sup>,</span>
              <span class="author-block">
                <a href="./">Qinglan Huang</a><sup>7</sup>,</span>
              <span class="author-block">
                <a href="https://canyuchen.com/">Canyu Chen</a><sup>9</sup>,</span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=ZYOhaGwAAAAJ&hl=zh-CN">Qinghao Ye</a><sup>5</sup>,</span>
              <span class="author-block">
                <a href="./">Zhihong Zhu</a><sup>8</sup>,</span>
              <span class="author-block">
                <a href="./">Yuqing Zhang</a><sup>11</sup>,</span>
              <span class="author-block">
                <a href="https://sites.harvard.edu/jzhou/">Jiawei Zhou</a><sup>12</sup>,</span>
              <span class="author-block">
                <a href="https://zhuokai-zhao.com/">Zhuokai Zhao</a><sup>2</sup>,</span><br>
              <span class="author-block">
                <a href="https://rmrafailov.github.io/">Rafael Rafailov</a><sup>3</sup>,</span>
              <span class="author-block">
                <a href="https://ai.stanford.edu/~cbfinn/">Chelsea Finn</a><sup>3</sup>,</span>
              <span class="author-block">
                <a href="https://www.huaxiuyao.io/">Huaxiu Yao</a><sup>1</sup>,</span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>UNC-Chapel Hill,</span>
              <span class="author-block"><sup>2</sup>University of Chicago,</span>
              <span class="author-block"><sup>3</sup>Stanford University,</span><br>
              <span class="author-block"><sup>4</sup>UCSC</span>
              <span class="author-block"><sup>5</sup>UCSD</span>
              <span class="author-block"><sup>6</sup>USTC</span>
              <span class="author-block"><sup>7</sup>ESSEC</span>
              <span class="author-block"><sup>8</sup>Peking University</span>
              <span class="author-block"><sup>9</sup>Illinois Tech</span><br>
              <span class="author-block"><sup>10</sup>Duke University</span>
              <span class="author-block"><sup>11</sup>University of Queensland</span>
              <span class="author-block"><sup>12</sup>Stony Brook University</span>
              <span class="author-block"><sup>13</sup>NUS</span>
            </div>

            <div class="is-size-6 publication-authors">
              <span class="author-block">*Equal contribution.</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2406.09961" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2406.09961" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Video Link. -->
                <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/MJ-Bench/MJ-Bench"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- Dataset Link. -->
                <span class="link-block">
                  <a href="https://huggingface.co/MJ-Bench"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="far fa-images"></i>
                    </span>
                    <span>Data</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://huggingface.co/collections/MJ-Bench/aligned-diffusion-model-via-dpo-667f8b71f35c3ff47acafd43"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="far fa-network-wired"></i>
                    </span>
                    <span>Model</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://huggingface.co/spaces/MJ-Bench/MJ-Bench-Leaderboard"
                      class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fab fa-trophy"></i>
                    </span>
                    <span>Leaderboard</span>
                  </a>
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <!-- <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video> -->
        <img src="./static/images/radar_plot.png" alt="Teaser image." style="width: 80%; height: auto;" />
        <h2 class="subtitle has-text-centered">
          <!-- <span class="dnerf">Nerfies</span> -->
          The real-world example. LMMs assist scientists and researchers in understanding, interpreting and creating
          charts during the reading and writing of academic papers.
          These models serve as assistants that enhance the comprehension and presentation of data in scholarly
          communications.
        </h2>
      </div>
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              While text-to-image models like DALLE-3 and Stable Diffusion are rapidly proliferating, they often encounter challenges such as hallucination, bias, and the production of unsafe, low-quality output. To effectively address these issues, it is crucial to align these models with desired behaviors based on feedback from a multimodal judge. Despite their significance, current multimodal judges frequently undergo inadequate evaluation of their capabilities and limitations, potentially leading to misalignment and unsafe fine-tuning outcomes.
            </p>
            <p>
              To address this issue, we introduce MJ-Bench, a novel benchmark which incorporates a comprehensive preference dataset to evaluate multimodal judges in providing feedback for image generation models across four key perspectives: alignment, safety, image quality, and bias. Specifically, we evaluate a large variety of multimodal judges including smaller-sized CLIP-based scoring models, open-source VLMs (e.g. LLaVA family), and close-source VLMs (e.g. GPT-4o, Claude 3) on each decomposed subcategory of our preference dataset. 
            </p>
            <p>
              Experiments reveal that close-source VLMs generally provide better feedback, with GPT-4o outperforming other judges in average. Compared with open-source VLMs, smaller-sized scoring models can provide better feedback regarding text-image alignment and image quality, while VLMs provide more accurate feedback regarding safety and generation bias due to their stronger reasoning capabilities.
              Further studies in feedback scale reveal that VLM judges can generally provide more accurate and stable feedback in natural language (Likert-scale) than numerical scales.
              Notably, human evaluations on end-to-end fine-tuned models using separate feedback from these multimodal judges provide similar conclusions, further confirming the effectiveness of \algname.
            </p>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->

      <!--/ Framework. -->
      <div class="hero-body">
        <!-- <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video> -->
        <img src="./static/images/overview.png" alt="Framework." style="width: 70%; height: auto;" />
        <h2 class="subtitle has-text-centered">
          <!-- <span class="dnerf">Nerfies</span> -->
          Overview of the proposed MJ-Bench dataset. To comprehensively evaluate the judge feedback provided by multimodal reward models for image generation, our preference dataset is structured around four key dimensions: text-image alignment, safety, image quality and artifacts, bias and fairness. Each dimension is thoroughly represented through various sub-scenarios that include distinct comparison pairs. These pairs are carefully chosen to highlight subtle, yet verifiable reasons such as incorrect facts, compromised quality, and unsafe implications that justify the preference.
        </h2>
      </div>
      <!--/ Framework. -->
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">



        <h2 class="title is-3">Leaderboard</h2>
        We conduct examination of 14 LMMs on ChartMimic, including 3 proprietary models and 11 open-weight
        models.

        <br>
        <br>

        <ul class="nav nav-tabs" id="myTab" role="tablist">
          <li class="nav-item" role="presentation">
            <button class="nav-link active" id="main-results-tab" data-bs-toggle="tab"
              data-bs-target="#benchmark-table-content" type="button" role="tab" aria-controls="main-results-tab"
              aria-selected="true">Main Result</button>
          </li>
          <li class="nav-item" role="presentation">
            <button class="nav-link" id="alignment-table-tab" data-bs-toggle="tab"
              data-bs-target="#alignment-table-content" type="button" role="tab" aria-controls="alignment-table-tab"
              aria-selected="false">Alignment</button>
          </li>
          <li class="nav-item" role="presentation">
            <button class="nav-link" id="safety-table-tab" data-bs-toggle="tab"
              data-bs-target="#safety-table-content" type="button" role="tab" aria-controls="safety-table-tab"
              aria-selected="false">Safety</button>
          </li>
        </ul>

        <div class="tab-content" id="myTabContent">
          <div class="tab-pane fade show active" id="benchmark-table-content" role="tabpanel"
            aria-labelledby="benchmark-table-content">

            <p class="mt-2 px-2">
              The ChartMimic leaderboard with <b>Direct Mimic</b> task. We also include
              the
              code
              execution success rate (Exec. Rate) and model size (Params).
            </p>

            <div id="benchmark-table"></div>
          </div>
          <div class="tab-pane fade" id="alignment-table-content" role="tabpanel"
            aria-labelledby="alignment-table-content">

            <p class="mt-2 px-2">
              The ChartMimic leaderboard with <b>Customized Mimic</b> task. We also include
              the
              code execution success rate (Exec. Rate) and model size (Params).
            </p>


            <div id="alignment-table"></div>
          </div>
          <div class="tab-pane fade" id="safety-table-content" role="tabpanel"
            aria-labelledby="safety-table-content">

            <p class="mt-2 px-2">
              The ChartMimic leaderboard with <b>Customized Mimic</b> task. We also include
              the
              code execution success rate (Exec. Rate) and model size (Params).
            </p>


            <div id="safety-table"></div>
          </div>
        </div>
        <br>
        <h2 class="subtitle">
          Please refer to our <a href="https://github.com/ChartMimic/ChartMimic">GitHub repo</a> to add your
          model to the leaderboard.
        </h2>
      </div>
    </div>
  </section>

  <section class="section" id="Data">
    <div class="container is-max-desktop content">
      <h2 class="title">Data</h2>
      <p>You can directly download our data from <a href="https://github.com/ChartMimic/ChartMimic">Huggingface
          datasets</a>. For guidance on how to access and utilize the data, please consult our instructions on <a
          href="https://huggingface.co/datasets/ChartMimic/ChartMimic">Github</a>.</p>
    </div>
  </section>

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{
      shi2024chartmimic,
      title={ChartMimic: Evaluating LMM’s Cross-Modal Reasoning Capability via Chart-to-Code Generation},
      author={Chufan Shi and Cheng Yang and Yaxin Liu and Bo Shui and Junjie Wang and Mohan Jing and Linran Xu and Xinyu Zhu and Siheng Li and Yuxiang Zhang and Gongye Liu and Xiaomei Nie and Deng Cai and Yujiu Yang},
      year={2024},
      journal={arXiv preprint arXiv:2406.09961},
      }</code>
  </pre>
    </div>
  </section>

  <section class="section" id="Contact">
    <div class="container is-max-desktop content">
      <h2 class="title">Contact Us</h2>
      <p>If you have any inquiries about ChartMimic, feel free to reach out to us at chartmimic@gmail.com or raise an
        issue on Github.</p>
    </div>
  </section>

  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="content is-small">
          This website templated is borrowed from <a href="https://github.com/nerfies/nerfies.github.io">nerfies</a> and
          <a href="https://xwang.dev/mint-bench/">MINT</a>.
        </div>
      </div>
    </div>
  </footer>

</body>

</html>