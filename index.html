<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description"
    content="A benchmark of Multimodal Reward Models for Text-to-Image Generation.">
  <meta name="keywords" content="Multimodal Code Generation, Large Multimodal Models">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>MJ-Bench: Is Your Multimodal Reward Model Really a Good Judge for Text-to-Image Generation?</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script> -->

  <meta name="viewport" content="width=device-width, initial-scale=1">

  <script src="https://cdn.jsdelivr.net/npm/chart.js@4.4.0/dist/chart.umd.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-datalabels@2.0.0"></script>
  <script
    src="https://cdn.jsdelivr.net/npm/chartjs-plugin-annotation@3.0.1/dist/chartjs-plugin-annotation.min.js"></script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link href="https://unpkg.com/tabulator-tables@5.5.2/dist/css/tabulator_bootstrap4.min.css" rel="stylesheet">
  <script type="text/javascript" src="https://unpkg.com/tabulator-tables@5.5.2/dist/js/tabulator.min.js"></script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.ico">

  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet"
    integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"
    integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p"
    crossorigin="anonymous"></script>

  <link href="https://unpkg.com/tabulator-tables@5.5.2/dist/css/tabulator_bootstrap4.min.css" rel="stylesheet">
  <script type="text/javascript" src="https://unpkg.com/tabulator-tables@5.5.2/dist/js/tabulator.min.js"></script>

  <script src="./static/js/benmark_table.js" type="module"></script>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <!-- <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script> -->
</head>

<body>

  <nav class="navbar navbar-default"
    style="background-color: rgb(119, 226, 255); border-bottom: 3px solid rgb(0, 128, 255); border-top: 3px solid rgb(0, 128, 255)">
    <div class="container-fluid">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
          data-target="#bs-example-navbar-collapse-1" aria-expanded="false">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a href="#" class="navbar-brand" style="color: rgb(0, 128, 255); font-weight: bolder; font-size: x-large;">
          <img src="static/images/MJBench.jpg" alt="Logo" style="width: auto; height: 20px;">
          MJ-Bench
        </a>
      </div>

      <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
        <ul class="nav navbar-nav">
          <li><a href="./index.html" style="color: rgb(0, 128, 255); font-weight: 800">MJ-Bench</a></li>
          <li><a href="./index.html#Abstract" style="color: rgb(0, 128, 255); font-weight: 800">Overview</a></li>
          <li><a href="./index.html#Leaderboard" style="color: rgb(0, 128, 255); font-weight: 800">Paper Overview</a></li>
          <!-- <li><a href="./index.html#examples" style="color: rgb(45, 45, 45); font-weight: 800">Examples</a></li> -->
          <!-- <li><a href="./index.html#ethics" style="color: rgb(45, 45, 45); font-weight: 800">Ethics</a></li> -->
          <!-- <li><a href="./index.html#citation" style="color: rgb(45, 45, 45); font-weight: 800">Cite</a></li> -->
        </ul>
      </div>
    </div>
  </nav>

  <!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <div style="display: flex; align-items: center; justify-content: center;">
              <!-- Logo image -->
              <!-- <img src="static/images/MJBench.jpg" alt="Logo" style="margin-right: -20px; width: auto; height: 70px;"> Adjust the src, height, and margin-right as needed -->
              <!-- Title -->
              <h1 class="title is-1 publication-title" style="font-size: 45px;">MJ-Bench: Is Your Multimodal Reward Model Really a Good Judge for Text-to-Image Generation?</h1>
            </div>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://billchan226.github.io/">Zhaorun Chen</a><sup>*1,2</sup>,</span>
              <span class="author-block">
                <a href="https://duyichao.github.io/">Yichao Du</a><sup>*6</sup>,</span>
              <span class="author-block">
                <a href="./">Zichen Wen</a><sup>*8</sup>,</span>
              <span class="author-block">
                <a href="https://yiyangzhou.github.io/">Yiyang Zhou</a><sup>*1</sup>,</span>
              <span class="author-block">
                <a href="https://gzcch.github.io/">Chenhang Cui</a><sup>13</sup>,</span>
              <span class="author-block">
                <a href="https://zzweng.github.io/">Zhenzhen Weng</a><sup>3</sup>,</span>
              <span class="author-block">
                <a href="https://www.haqtu.me/">Haoqin Tu</a><sup>4</sup>,</span>
              <span class="author-block">
                <a href="https://alecwangcq.github.io/">Chaoqi Wang</a><sup>2</sup>,</span><br>
              <span class="author-block">
                <a href="https://scholars.duke.edu/person/zhengwei.tong">Zhengwei Tong</a><sup>10</sup>,</span>
              <span class="author-block">
                <a href="./">Qinglan Huang</a><sup>7</sup>,</span>
              <span class="author-block">
                <a href="https://canyuchen.com/">Canyu Chen</a><sup>9</sup>,</span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=ZYOhaGwAAAAJ&hl=zh-CN">Qinghao Ye</a><sup>5</sup>,</span>
              <span class="author-block">
                <a href="./">Zhihong Zhu</a><sup>8</sup>,</span>
              <span class="author-block">
                <a href="./">Yuqing Zhang</a><sup>11</sup>,</span>
              <span class="author-block">
                <a href="https://sites.harvard.edu/jzhou/">Jiawei Zhou</a><sup>12</sup>,</span>
              <span class="author-block">
                <a href="https://zhuokai-zhao.com/">Zhuokai Zhao</a><sup>2</sup>,</span><br>
              <span class="author-block">
                <a href="https://rmrafailov.github.io/">Rafael Rafailov</a><sup>3</sup>,</span>
              <span class="author-block">
                <a href="https://ai.stanford.edu/~cbfinn/">Chelsea Finn</a><sup>3</sup>,</span>
              <span class="author-block">
                <a href="https://www.huaxiuyao.io/">Huaxiu Yao</a><sup>1</sup>,</span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>UNC-Chapel Hill,</span>
              <span class="author-block"><sup>2</sup>University of Chicago,</span>
              <span class="author-block"><sup>3</sup>Stanford University,</span><br>
              <span class="author-block"><sup>4</sup>UCSC</span>
              <span class="author-block"><sup>5</sup>UCSD</span>
              <span class="author-block"><sup>6</sup>USTC</span>
              <span class="author-block"><sup>7</sup>ESSEC</span>
              <span class="author-block"><sup>8</sup>Peking University</span>
              <span class="author-block"><sup>9</sup>Illinois Tech</span><br>
              <span class="author-block"><sup>10</sup>Duke University</span>
              <span class="author-block"><sup>11</sup>University of Queensland</span>
              <span class="author-block"><sup>12</sup>Stony Brook University</span>
              <span class="author-block"><sup>13</sup>NUS</span>
            </div>

            <div class="is-size-6 publication-authors">
              <span class="author-block">*Equal contribution.</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2406.09961" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2406.09961" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Video Link. -->
                <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/MJ-Bench/MJ-Bench"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- Dataset Link. -->
                <span class="link-block">
                  <a href="https://huggingface.co/MJ-Bench"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="far fa-images"></i>
                    </span>
                    <span>Data</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://huggingface.co/collections/MJ-Bench/aligned-diffusion-model-via-dpo-667f8b71f35c3ff47acafd43"
                    class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <p style="font-size:18px">ü§ó</p>
                  </span>
                    <span>Model</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://huggingface.co/spaces/MJ-Bench/MJ-Bench-Leaderboard"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <p style="font-size:18px">üèÜ</p>
                    </span>
                    <span>Leaderboard</span>
                  </a>
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body" style="display: flex; justify-content: center; align-items: center; flex-direction: column;">
        <!-- <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video> -->
        <img src="./static/images/radar_plot.png" alt="Teaser image." style="width: 80%; height: auto;" />
        <h2 class="subtitle has-text-left" style="text-align: left; width: 100%;">
          <!-- <span class="dnerf">Nerfies</span> -->
          We evaluate a large variety of multimodal judges on <b>MJ-Bench</b> dataset. We compare their feedback over four comprehensive perspectives, each decomposed into multiple sub-categories. Additionally, we study the effectiveness of the feedback under different scales and input modes.
        </h2>
      </div>
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              While text-to-image models like DALLE-3 and Stable Diffusion are rapidly proliferating, they often encounter challenges such as hallucination, bias, and the production of unsafe, low-quality output. To effectively address these issues, it is crucial to align these models with desired behaviors based on feedback from a multimodal judge. Despite their significance, current multimodal judges frequently undergo inadequate evaluation of their capabilities and limitations, potentially leading to misalignment and unsafe fine-tuning outcomes.
            </p>
            <p>
              To address this issue, we introduce <b>MJ-Bench</b>, a novel benchmark which incorporates a comprehensive preference dataset to evaluate multimodal judges in providing feedback for image generation models across four key perspectives: alignment, safety, image quality, and bias. Specifically, we evaluate a large variety of multimodal judges including smaller-sized CLIP-based scoring models, open-source VLMs (e.g. LLaVA family), and close-source VLMs (e.g. GPT-4o, Claude 3) on each decomposed subcategory of our preference dataset. 
            </p>
            <p>
              Experiments reveal that close-source VLMs generally provide better feedback, with GPT-4o outperforming other judges in average. Compared with open-source VLMs, smaller-sized scoring models can provide better feedback regarding text-image alignment and image quality, while VLMs provide more accurate feedback regarding safety and generation bias due to their stronger reasoning capabilities.
              Further studies in feedback scale reveal that VLM judges can generally provide more accurate and stable feedback in natural language (Likert-scale) than numerical scales.
              Notably, human evaluations on end-to-end fine-tuned models using separate feedback from these multimodal judges provide similar conclusions, further confirming the effectiveness of <b>MJ-Bench</b>.
            </p>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->

      <!--/ Framework. -->
      <div class="hero-body" style="display: flex; justify-content: center; align-items: center; flex-direction: column;">
        <!-- <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video> -->
        <img src="./static/images/dataset_overview.png" alt="Framework." style="width: 70%; height: auto;" />
        <h2 class="subtitle has-text-left" style="text-align: left; width: 100%;">
          <!-- <span class="dnerf">Nerfies</span> -->
          Overview of the proposed <b>MJ-Bench</b> dataset. To comprehensively evaluate the judge feedback provided by multimodal reward models for image generation, our preference dataset is structured around four key dimensions: text-image alignment, safety, image quality and artifacts, bias and fairness. Each dimension is thoroughly represented through various sub-scenarios that include distinct comparison pairs. These pairs are carefully chosen to highlight subtle, yet verifiable reasons such as incorrect facts, compromised quality, and unsafe implications that justify the preference.
        </h2>
      </div>
      <!--/ Framework. -->
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
        <div class="hero-body">
            <h2 class="title is-3">Leaderboard</h2>
            <p>
                We compare over 22 multimodal judges on <b>MJ-Bench</b> dataset. The leaderboard is updated daily to reflect the latest performance of each model. The leaderboard is based on the average accuracy (%) with and without ties for alignment, safety, and artifact. We evaluate preference biases over three metrics, i.e. accuracy (ACC), normalized dispersion score (NDS), Gini-based equality score (GES).
            </p>
            <br>
            <ul class="nav nav-tabs" id="myTab" role="tablist">
                <li class="nav-item" role="presentation">
                    <button class="nav-link active" id="main-results-tab" data-bs-toggle="tab" data-bs-target="#benchmark-table-content" type="button" role="tab" aria-controls="benchmark-table-content" aria-selected="true">Main Result</button>
                </li>
                <li class="nav-item" role="presentation">
                    <button class="nav-link" id="human-table-tab" data-bs-toggle="tab" data-bs-target="#human-table-content" type="button" role="tab" aria-controls="human-table-content" aria-selected="false">Human-Eval</button>
                </li>
                <li class="nav-item" role="presentation">
                    <button class="nav-link" id="alignment-table-tab" data-bs-toggle="tab" data-bs-target="#alignment-table-content" type="button" role="tab" aria-controls="alignment-table-content" aria-selected="false">Alignment</button>
                </li>
                <li class="nav-item" role="presentation">
                    <button class="nav-link" id="safety-table-tab" data-bs-toggle="tab" data-bs-target="#safety-table-content" type="button" role="tab" aria-controls="safety-table-content" aria-selected="false">Safety</button>
                </li>
                <li class="nav-item" role="presentation">
                    <button class="nav-link" id="quality-table-tab" data-bs-toggle="tab" data-bs-target="#quality-table-content" type="button" role="tab" aria-controls="quality-table-content" aria-selected="false">Quality</button>
                </li>
                <li class="nav-item" role="presentation">
                    <button class="nav-link" id="bias-table-tab" data-bs-toggle="tab" data-bs-target="#bias-table-content" type="button" role="tab" aria-controls="bias-table-content" aria-selected="false">Bias</button>
                </li>
            </ul>

            <div class="tab-content" id="myTabContent">
                <div class="tab-pane fade show active" id="benchmark-table-content" role="tabpanel" aria-labelledby="main-results-tab">
                    <p class="mt-2 px-2">
                        Evaluation of three types of multimodal judges across four perspectives on <b>MJ-Bench</b> dataset. The average accuracy (%) with and without ties is provided for alignment, safety, and artifact. We evaluate preference biases over three metrics, i.e. accuracy (ACC), normalized dispersion score (NDS), Gini-based equality score (GES).
                    </p>
                    <div id="benchmark-table"></div>
                </div>
                <div class="tab-pane fade" id="human-table-content" role="tabpanel" aria-labelledby="human-table-tab">
                    <p class="mt-2 px-2">
                        Human evaluation result on the generated images from six fine-tuned SD-v1.5 model using the feedback from six multimodal judges, i.e. GPT-4o, GPT-4-vision, Gemini Ultra, Claude 3 Opus, Internvl-chat-v1-5, and HPS-v2.1. Specifically, we consider the following four metrics: ranking over fixed seed (<b>FR</b>), ranking over random seed (<b>RR</b>), average ranking (<b>AR</b>), and average voting (<b>AV</b>).
                    </p>
                    <div id="human-table"></div>
                </div>
                <div class="tab-pane fade" id="alignment-table-content" role="tabpanel" aria-labelledby="alignment-table-tab">
                    <p class="mt-2 px-2">
                        The detailed evaluation result of all multimodal judges on <b>alignment</b> perspective. The feedback are provided in numerical scale of range [0, 10]. Specifically, we study their individual performance over five alignment objectives: object (existence), attribute, action, location, and count.
                    </p>
                    <div id="alignment-table"></div>
                </div>
                <div class="tab-pane fade" id="safety-table-content" role="tabpanel" aria-labelledby="safety-table-tab">
                    <p class="mt-2 px-2">
                        The detailed evaluation result of all multimodal judges on <b>safety</b> perspective. The feedback are provided in numerical scale of range [0, 10]. Specifically, we study their individual performance over two safety objectives: toxicity (crime, shocking, and disgust) and NSFW (evident, evasive, and subtle).
                    </p>
                    <div id="safety-table"></div>
                </div>
                <div class="tab-pane fade" id="quality-table-content" role="tabpanel" aria-labelledby="quality-table-tab">
                    <p class="mt-2 px-2">
                        The detailed evaluation result of all multimodal judges on <b>quality</b> perspective. The feedback is provided in numerical scale of range [0, 10]. Specifically, we study their individual performance over two quality objectives: distortion (including human face, human limb, and object), and blurry (including defocused and motion).
                    </p>
                    <div id="quality-table"></div>
                </div>
                <div class="tab-pane fade" id="bias-table-content" role="tabpanel" aria-labelledby="bias-table-tab">
                    <p class="mt-2 px-2">
                        The detailed evaluation result of all multimodal judges on <b>bias</b> perspective. The feedback are provided in different scales including numerical scales ([0-5], and [0-10]) and Likert scale: [Extremely Poor, Poor, Average, Good, Outstanding]. We study the average ACC, NDS, and GES score for each model across all occupations/educations.
                    </p>
                    <div id="bias-table"></div>
                </div>
            </div>
            <br>
            <h2 class="subtitle">
                Please refer to our <a href="https://huggingface.co/spaces/MJ-Bench/MJ-Bench-Leaderboard">Huggingface Leaderboard</a> to add your model to the leaderboard.
            </h2>
        </div>
    </div>
</section>

  <section class="section" id="Data">
    <div class="container is-max-desktop content">
      <h2 class="title">Data</h2>
      <p>You can directly download our data from <a href="https://huggingface.co/MJ-Bench">Huggingface
          datasets</a>. For guidance on how to access and utilize the data, please consult our instructions on <a
          href="https://github.com/MJ-Bench/MJ-Bench">Github</a>.</p>
    </div>
  </section>

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{
  chen2024mjbench,
      }</code>
  </pre>
    </div>
  </section>

  <section class="section" id="Contact">
    <div class="container is-max-desktop content">
      <h2 class="title">Contact Us</h2>
      <p>If you have any inquiries about ChartMimic, feel free to reach out to us at chartmimic@gmail.com or raise an
        issue on Github.</p>
    </div>
  </section>

  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="content is-small">
          This website templated is borrowed from <a href="https://github.com/nerfies/nerfies.github.io">nerfies</a> and
          <a href="https://xwang.dev/mint-bench/">MINT</a>.
        </div>
      </div>
    </div>
  </footer>

</body>

</html>